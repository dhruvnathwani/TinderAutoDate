{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "import random\n",
    "from time import sleep\n",
    "from os import listdir, rename\n",
    "from os.path import isfile, join\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "from object_detection.utils import ops as utils_ops\n",
    "import os\n",
    "import person_detector\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wrapper to call the API easily by defining classes\n",
    "TINDER_URL = \"https://api.gotinder.com\"\n",
    "geolocator = Nominatim(user_agent=\"auto-tinder\")\n",
    "PROF_FILE = \"./profiles.txt\"\n",
    "\n",
    "class Person(object):\n",
    "\n",
    "    def __init__(self, data, api):\n",
    "        self._api = api\n",
    "\n",
    "        self.id = data[\"_id\"]\n",
    "        self.name = data.get(\"name\", \"Unknown\")\n",
    "\n",
    "        self.bio = data.get(\"bio\", \"\")\n",
    "        self.distance = data.get(\"distance_mi\", 0) / 1.60934\n",
    "\n",
    "        self.birth_date = datetime.datetime.strptime(data[\"birth_date\"], '%Y-%m-%dT%H:%M:%S.%fZ') if data.get(\n",
    "            \"birth_date\", False) else None\n",
    "        self.gender = [\"Male\", \"Female\", \"Unknown\"][data.get(\"gender\", 2)]\n",
    "\n",
    "        self.images = list(map(lambda photo: photo[\"url\"], data.get(\"photos\", [])))\n",
    "\n",
    "        self.jobs = list(\n",
    "            map(lambda job: {\"title\": job.get(\"title\", {}).get(\"name\"), \"company\": job.get(\"company\", {}).get(\"name\")}, data.get(\"jobs\", [])))\n",
    "        self.schools = list(map(lambda school: school[\"name\"], data.get(\"schools\", [])))\n",
    "\n",
    "        if data.get(\"pos\", False):\n",
    "            self.location = geolocator.reverse(f'{data[\"pos\"][\"lat\"]}, {data[\"pos\"][\"lon\"]}')\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.id}  -  {self.name} ({self.birth_date.strftime('%d.%m.%Y')})\"\n",
    "\n",
    "\n",
    "    def like(self):\n",
    "        return self._api.like(self.id)\n",
    "\n",
    "    def dislike(self):\n",
    "        return self._api.dislike(self.id)\n",
    "\n",
    "    def download_images(self, folder=\".\", sleep_max_for=0):\n",
    "        with open(PROF_FILE, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            if self.id in lines:\n",
    "                return\n",
    "        with open(PROF_FILE, \"a\") as f:\n",
    "            f.write(self.id+\"\\r\\n\")\n",
    "        index = -1\n",
    "        for image_url in self.images:\n",
    "            index += 1\n",
    "            req = requests.get(image_url, stream=True)\n",
    "            if req.status_code == 200:\n",
    "                with open(f\"{folder}/{self.id}_{self.name}_{index}.jpeg\", \"wb\") as f:\n",
    "                    f.write(req.content)\n",
    "            sleep(random.random()*sleep_max_for)\n",
    "    \n",
    "    def predict_likeliness(self, classifier, sess):\n",
    "        ratings = []\n",
    "        for image in self.images:\n",
    "            req = requests.get(image, stream=True)\n",
    "            tmp_filename = f\"./images/tmp/run.jpg\"\n",
    "            if req.status_code == 200:\n",
    "                with open(tmp_filename, \"wb\") as f:\n",
    "                    f.write(req.content)\n",
    "            img = person_detector.get_person(tmp_filename, sess)\n",
    "            if img:\n",
    "                img = img.convert('L')\n",
    "                img.save(tmp_filename, \"jpeg\")\n",
    "                certainty = classifier.classify(tmp_filename)\n",
    "                pos = certainty[\"positive\"]\n",
    "                ratings.append(pos)\n",
    "        ratings.sort(reverse=True)\n",
    "        ratings = ratings[:5]\n",
    "        if len(ratings) == 0:\n",
    "            return 0.001\n",
    "        return ratings[0]*0.6 + sum(ratings[1:])/len(ratings[1:])*0.4\n",
    "\n",
    "\n",
    "\n",
    "class tinderAPI():\n",
    "\n",
    "    def __init__(self, token):\n",
    "        self._token = token\n",
    "\n",
    "    def profile(self):\n",
    "        data = requests.get(TINDER_URL + \"/v2/profile?include=account%2Cuser\", headers={\"X-Auth-Token\": self._token}).json()\n",
    "        return Profile(data[\"data\"], self)\n",
    "\n",
    "    def matches(self, limit=10):\n",
    "        data = requests.get(TINDER_URL + f\"/v2/matches?count={limit}\", headers={\"X-Auth-Token\": self._token}).json()\n",
    "        return list(map(lambda match: Person(match[\"person\"], self), data[\"data\"][\"matches\"]))\n",
    "\n",
    "    def like(self, user_id):\n",
    "        data = requests.get(TINDER_URL + f\"/like/{user_id}\", headers={\"X-Auth-Token\": self._token}).json()\n",
    "        return {\n",
    "            \"is_match\": data[\"match\"],\n",
    "            \"liked_remaining\": data[\"likes_remaining\"]\n",
    "        }\n",
    "\n",
    "    def dislike(self, user_id):\n",
    "        requests.get(TINDER_URL + f\"/pass/{user_id}\", headers={\"X-Auth-Token\": self._token}).json()\n",
    "        return True\n",
    "\n",
    "    def nearby_persons(self):\n",
    "        data = requests.get(TINDER_URL + \"/v2/recs/core\", headers={\"X-Auth-Token\": self._token}).json()\n",
    "        return list(map(lambda user: Person(user[\"user\"], self), data[\"data\"][\"results\"]))\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self, graph, labels):\n",
    "\n",
    "        self._graph = self.load_graph(graph)\n",
    "        self._labels = self.load_labels(labels)\n",
    "\n",
    "        self._input_operation = self._graph.get_operation_by_name(\"import/Placeholder\")\n",
    "        self._output_operation = self._graph.get_operation_by_name(\"import/final_result\")\n",
    "\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "\n",
    "    def classify(self, file_name):\n",
    "        t = self.read_tensor_from_image_file(file_name)\n",
    "\n",
    "        # Open up a new tensorflow session and run it on the input\n",
    "        results = self._session.run(self._output_operation.outputs[0], {self._input_operation.outputs[0]: t})\n",
    "        results = np.squeeze(results)\n",
    "\n",
    "        # Sort the output predictions by prediction accuracy\n",
    "        top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "        result = {}\n",
    "        for i in top_k:\n",
    "            result[self._labels[i]] = results[i]\n",
    "\n",
    "        # Return sorted result tuples\n",
    "        return result\n",
    "\n",
    "    def close(self):\n",
    "        self._session.close()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_graph(model_file):\n",
    "        graph = tf.Graph()\n",
    "        graph_def = tf.GraphDef()\n",
    "        with open(model_file, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "        with graph.as_default():\n",
    "            tf.import_graph_def(graph_def)\n",
    "        return graph\n",
    "\n",
    "    @staticmethod\n",
    "    def load_labels(label_file):\n",
    "        label = []\n",
    "        proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "        for l in proto_as_ascii_lines:\n",
    "            label.append(l.rstrip())\n",
    "        return label\n",
    "\n",
    "    @staticmethod\n",
    "    def read_tensor_from_image_file(file_name,\n",
    "                                    input_height=299,\n",
    "                                    input_width=299,\n",
    "                                    input_mean=0,\n",
    "                                    input_std=255):\n",
    "        input_name = \"file_reader\"\n",
    "        file_reader = tf.read_file(file_name, input_name)\n",
    "        image_reader = tf.image.decode_jpeg(\n",
    "            file_reader, channels=3, name=\"jpeg_reader\")\n",
    "        float_caster = tf.cast(image_reader, tf.float32)\n",
    "        dims_expander = tf.expand_dims(float_caster, 0)\n",
    "        resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "        normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "        sess = tf.Session()\n",
    "        result = sess.run(normalized)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Get and download pictures for our dataset\n",
    "\n",
    "token = ''\n",
    "\n",
    "# Instantiate the API\n",
    "api = tinderAPI(token)\n",
    "\n",
    "# While true, loop through all people and download pics\n",
    "while True:\n",
    "    persons = api.nearby_persons()\n",
    "    for person in persons:\n",
    "        print(person)\n",
    "        person.download_images(folder='./Images/Unclassified', sleep_max_for=random.random()*3)\n",
    "        sleep(random.random()*10)\n",
    "\n",
    "    sleep(random.random()*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image classifier GUI\n",
    "\n",
    "IMAGE_FOLDER = \"./images/unclassified\"\n",
    "\n",
    "images = [f for f in listdir(IMAGE_FOLDER) if isfile(join(IMAGE_FOLDER, f))]\n",
    "unclassified_images = filter(lambda image: not (image.startswith(\"0_\") or image.startswith(\"1_\")), images)\n",
    "current = None\n",
    "\n",
    "def next_img():\n",
    "    global current, unclassified_images\n",
    "    try:\n",
    "        current = next(unclassified_images)\n",
    "    except StopIteration:\n",
    "        root.quit()\n",
    "    #print(current)\n",
    "    pil_img = Image.open(IMAGE_FOLDER+\"/\"+current)\n",
    "    width, height = pil_img.size\n",
    "    max_height = 1000\n",
    "    if height > max_height:\n",
    "        resize_factor = max_height / height\n",
    "        pil_img = pil_img.resize((int(width*resize_factor), int(height*resize_factor)), resample=Image.LANCZOS)\n",
    "    img_tk = ImageTk.PhotoImage(pil_img)\n",
    "    img_label.img = img_tk\n",
    "    img_label.config(image=img_label.img)\n",
    "\n",
    "def positive(arg):\n",
    "    global current\n",
    "    rename(IMAGE_FOLDER+\"/\"+current, IMAGE_FOLDER+\"/1_\"+current)\n",
    "    next_img()\n",
    "\n",
    "def negative(arg):\n",
    "    global current\n",
    "    rename(IMAGE_FOLDER + \"/\" + current, IMAGE_FOLDER + \"/0_\" + current)\n",
    "    next_img()\n",
    "\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "img_label = tk.Label(root)\n",
    "img_label.pack()\n",
    "img_label.bind(\"<Button-1>\", positive)\n",
    "img_label.bind(\"<Button-3>\", negative)\n",
    "\n",
    "btn = tk.Button(root, text='Next image', command=next_img)\n",
    "\n",
    "next_img() # load first image\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and sort our images after they have been classified\n",
    "\n",
    "IMAGE_FOLDER = \"./images/unclassified\"\n",
    "POS_FOLDER = \"./images/classified/positive\"\n",
    "NEG_FOLDER = \"./images/classified/negative\"\n",
    "\n",
    "\n",
    "\n",
    "detection_graph = person_detector.open_graph()\n",
    "\n",
    "images = [f for f in os.listdir(IMAGE_FOLDER) if os.path.isfile(os.path.join(IMAGE_FOLDER, f))]\n",
    "positive_images = filter(lambda image: (image.startswith(\"1_\")), images)\n",
    "negative_images = filter(lambda image: (image.startswith(\"0_\")), images)\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        for pos in positive_images:\n",
    "\n",
    "            try:\n",
    "                old_filename = IMAGE_FOLDER + \"/\" + pos\n",
    "                new_filename = POS_FOLDER + \"/\" + pos[:-5] + \".jpg\"\n",
    "                if not os.path.isfile(new_filename):\n",
    "                    img = person_detector.get_person(old_filename, sess)\n",
    "                    if not img:\n",
    "                        continue\n",
    "                    img = img.convert('L')\n",
    "                    img.save(new_filename, \"jpeg\")\n",
    "\n",
    "            except:\n",
    "                next\n",
    "\n",
    "        for neg in negative_images:\n",
    "\n",
    "            try:\n",
    "                old_filename = IMAGE_FOLDER + \"/\" + neg\n",
    "                new_filename = NEG_FOLDER + \"/\" + neg[:-5] + \".jpg\"\n",
    "                if not os.path.isfile(new_filename):\n",
    "                    img = person_detector.get_person(old_filename, sess)\n",
    "                    if not img:\n",
    "                        continue\n",
    "                    img = img.convert('L')\n",
    "                    img.save(new_filename, \"jpeg\")\n",
    "\n",
    "            except:\n",
    "                next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on autopilot\n",
    "\n",
    "token = ''\n",
    "\n",
    "# Instantiate the API\n",
    "api = tinderAPI(token)\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.Session(config=config)\n",
    "\n",
    "detection_graph = person_detector.open_graph()\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        classifier = Classifier(graph=\"./tf/training_output/retrained_graph.pb\",\n",
    "                                labels=\"./tf/training_output/retrained_labels.txt\")\n",
    "\n",
    "        sent_likes = 0\n",
    "\n",
    "        max_likes = 20\n",
    "\n",
    "        while sent_likes < max_likes:\n",
    "            #try:\n",
    "            persons = api.nearby_persons()\n",
    "\n",
    "            for person in persons:\n",
    "\n",
    "                try:\n",
    "                    #print(person)\n",
    "\n",
    "                    print('Likes Sent: ' + str(sent_likes))\n",
    "\n",
    "                    webbrowser.open(person.images[0])\n",
    "\n",
    "                    score = person.predict_likeliness(classifier, sess)\n",
    "\n",
    "                    #print(\"ID: \", person.id)\n",
    "                    print(\"Name: \", person.name)\n",
    "                    #print(\"Schools: \", person.schools)\n",
    "                    #print(\"Images: \", person.images)\n",
    "                    print(score)\n",
    "\n",
    "                    if score > 0.84:\n",
    "                        res = person.like()\n",
    "                        print(\"LIKE\")\n",
    "\n",
    "                        webbrowser.open(person.images[0])\n",
    "\n",
    "                        sent_likes += 1\n",
    "\n",
    "                        \n",
    "                    else:\n",
    "                        res = person.dislike()\n",
    "                        print(\"DISLIKE\")\n",
    "\n",
    "                    print('-----------------------------')\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('nntrainer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8d8317ce1814a820e4cfde15cf6466e096510ddee52723197796eb04daa03b27"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
